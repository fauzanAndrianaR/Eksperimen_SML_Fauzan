name: Heart Data Preprocessing Workflow

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]
  workflow_dispatch:

jobs:
  preprocess:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy scikit-learn matplotlib seaborn jupyter

      - name: Verify dataset structure
        run: |
          head -5 *.csv || echo "No CSV files found"

      - name: Run data preprocessing
        run: |
          cd preprocessing
          python automate_fauzan.py

      - name: Verify preprocessing output
        run: |
          ls -la preprocessing/dataset_preprocessing/
          echo "Training data shape:"
          python -c "import pandas as pd; print(pd.read_csv('preprocessing/dataset_preprocessing/X_train.csv').shape)"

      - name: Upload preprocessed data artifacts
        uses: actions/upload-artifact@v4
        with:
          name: preprocessed-heart-data
          path: preprocessing/dataset_preprocessing/
          retention-days: 30

      - name: Create preprocessing report
        run: |
          echo "# Preprocessing Report" > preprocessing_report.md
          echo "- Dataset: Heart Classification" >> preprocessing_report.md
          echo "- Date: $(date)" >> preprocessing_report.md
          echo "- Status: Completed" >> preprocessing_report.md
          python -c "
          import pandas as pd
          import json
          X_train = pd.read_csv('preprocessing/dataset_preprocessing/X_train.csv')
          y_train = pd.read_csv('preprocessing/dataset_preprocessing/y_train.csv')
          with open('preprocessing/dataset_preprocessing/feature_info.json', 'r') as f:
              info = json.load(f)
          print(f'- Training samples: {len(X_train)}')
          print(f'- Features: {len(X_train.columns)}')
          print(f'- Classes: {info[\"target_classes\"]}')
          " >> preprocessing_report.md

      - name: Upload preprocessing report
        uses: actions/upload-artifact@v4
        with:
          name: preprocessing-report
          path: preprocessing_report.md

  validate:
    needs: preprocess
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pandas numpy scikit-learn

      - name: Download preprocessed data
        uses: actions/download-artifact@v4
        with:
          name: preprocessed-heart-data
          path: ./validation_data/

      - name: Validate preprocessed data
        run: |
          python -c "
          import pandas as pd
          import numpy as np

          # Load data
          X_train = pd.read_csv('validation_data/X_train.csv')
          X_test = pd.read_csv('validation_data/X_test.csv')
          y_train = pd.read_csv('validation_data/y_train.csv')
          y_test = pd.read_csv('validation_data/y_test.csv')

          # Validation checks
          assert X_train.shape[1] == X_test.shape[1], 'Feature count mismatch'
          assert len(X_train) == len(y_train), 'Training data length mismatch'
          assert len(X_test) == len(y_test), 'Test data length mismatch'
          assert not X_train.isnull().any().any(), 'Training data has null values'
          assert not X_test.isnull().any().any(), 'Test data has null values'
          assert set(y_train['target'].unique()) == set(y_test['target'].unique()), 'Class distribution issue'

          print('âœ… All validation checks passed!')
          print(f'Training data: {X_train.shape}')
          print(f'Test data: {X_test.shape}')
          print(f'Classes: {sorted(y_train[\"target\"].unique())}')
          "